{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gym==0.21\n",
    "#!pip install tensorflow==1.14\n",
    "#!pip install \"ray[rllib]==0.8.4\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_economist import foundation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tutorials.utils import plotting  # plotting utilities for visualizing env. state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a configuration (dictionary) for the \"gather-trade-build\" environment.\n",
    "\n",
    "env_config_dict = {\n",
    "    # ===== SCENARIO CLASS =====\n",
    "    # Which Scenario class to use: the class's name in the Scenario Registry (foundation.scenarios).\n",
    "    # The environment object will be an instance of the Scenario class.\n",
    "    'scenario_name': 'layout_from_file/hetero_agents',\n",
    "    \n",
    "    # ===== COMPONENTS =====\n",
    "    # Which components to use (specified as list of (\"component_name\", {component_kwargs}) tuples).\n",
    "    #   \"component_name\" refers to the Component class's name in the Component Registry (foundation.components)\n",
    "    #   {component_kwargs} is a dictionary of kwargs passed to the Component class\n",
    "    # The order in which components reset, step, and generate obs follows their listed order below.\n",
    "    'components': [\n",
    "        # (1) Building houses\n",
    "        ('Build', {\n",
    "            'skill_dist':                   'pareto', \n",
    "            'payment_max_skill_multiplier': 3,\n",
    "            'build_labor':                  10,\n",
    "            'payment':                      10\n",
    "        }),\n",
    "        # (2) Trading collectible resources\n",
    "        ('ContinuousDoubleAuction', {\n",
    "            'max_bid_ask':    10,\n",
    "            'order_labor':    0.25,\n",
    "            'max_num_orders': 5,\n",
    "            'order_duration': 50\n",
    "        }),\n",
    "        # (3) Movement and resource collection\n",
    "        ('Gather', {\n",
    "            'move_labor':    1,\n",
    "            'collect_labor': 1,\n",
    "            'skill_dist':    'pareto'\n",
    "        }),\n",
    "        # (4) Planner\n",
    "        ('PeriodicBracketTax', {\n",
    "            'period':          250,\n",
    "            'bracket_spacing': 'us-federal',\n",
    "            'usd_scaling':     1000,\n",
    "            'disable_taxes':   False\n",
    "        })\n",
    "    ],\n",
    "    \n",
    "    # ===== SCENARIO CLASS ARGUMENTS =====\n",
    "    # (optional) kwargs that are added by the Scenario class (i.e. not defined in BaseEnvironment)\n",
    "    'env_layout_file': 'quadrant_25x25_20each_30clump.txt',\n",
    "    'starting_agent_coin': 10,\n",
    "    'fixed_four_skill_and_loc': True,\n",
    "    \n",
    "    # ===== STANDARD ARGUMENTS ======\n",
    "    # kwargs that are used by every Scenario class (i.e. defined in BaseEnvironment)\n",
    "    'n_agents': 3,          # Number of non-planner agents (must be > 1)\n",
    "    'world_size': [25, 25], # [Height, Width] of the env world\n",
    "    'episode_length': 759, # Number of timesteps per episode\n",
    "    \n",
    "    # In multi-action-mode, the policy selects an action for each action subspace (defined in component code).\n",
    "    # Otherwise, the policy selects only 1 action.\n",
    "    'multi_action_mode_agents': False,\n",
    "    'multi_action_mode_planner': True,\n",
    "    \n",
    "    # When flattening observations, concatenate scalar & vector observations before output.\n",
    "    # Otherwise, return observations with minimal processing.\n",
    "    'flatten_observations': True,\n",
    "    # When Flattening masks, concatenate each action subspace mask into a single array.\n",
    "    # Note: flatten_masks = True is required for masking action logits in the code below.\n",
    "    'flatten_masks': True,\n",
    "    \n",
    "    # How often to save the dense logs\n",
    "    'dense_log_frequency': 1,\n",
    "    \n",
    "    # new\n",
    "    \"env_weighting\" :[.01, 0.004, -.002],#needs to have len of n agents\n",
    "    #{0: -0.2625000000000002, 1: -0.05250000000000021, 2: -0.2625000000000002, 'p': 0.0}\n",
    "\n",
    "    \"equ_weighting\": [.5, -.1, .1],\n",
    "    \"mobile_agent_class\": \"HeteroMobileAgent\",#HeteroMobileAgent, BasicMobileAgent\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coin\n",
      "Stone\n",
      "Wood\n"
     ]
    }
   ],
   "source": [
    "env = foundation.make_env_instance(**env_config_dict)\n",
    "obs = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0 coin-per-house: 14.87301326696934  evironment weighting: 0.01  equality weighting: 0.5\n",
      "Agent 1 coin-per-house: 11.81445367502974  evironment weighting: 0.004  equality weighting: -0.1\n",
      "Agent 2 coin-per-house: 20.79461173785582  evironment weighting: -0.002  equality weighting: 0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for agent in env.world.agents:\n",
    "    print('Agent {} coin-per-house: {}  evironment weighting: {}  equality weighting: {}'.format(\n",
    "        agent.idx, agent.state['build_payment'], agent.env_weighting, agent.equality\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.world.agents[0].action_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The code for sampling actions (this cell), and playing an episode (below) are general.  \n",
    "# That is, it doesn't depend on the Scenario and Component classes used in the environment!\n",
    "\n",
    "def sample_random_action(agent, mask):\n",
    "    \"\"\"Sample random UNMASKED action(s) for agent.\"\"\"\n",
    "    # Return a list of actions: 1 for each action subspace\n",
    "    if agent.multi_action_mode:\n",
    "        split_masks = np.split(mask, agent.action_spaces.cumsum()[:-1])\n",
    "        return [np.random.choice(np.arange(len(m_)), p=m_/m_.sum()) for m_ in split_masks]\n",
    "\n",
    "    # Return a single action\n",
    "    else:\n",
    "        return np.random.choice(np.arange(agent.action_spaces), p=mask/mask.sum())\n",
    "\n",
    "def sample_random_actions(env, obs):\n",
    "    \"\"\"Samples random UNMASKED actions for each agent in obs.\"\"\"\n",
    "        \n",
    "    actions = {\n",
    "        a_idx: sample_random_action(env.get_agent(a_idx), a_obs['action_mask'])\n",
    "        for a_idx, a_obs in obs.items()\n",
    "    }\n",
    "\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 10, '1': 3, '2': 8, 'p': [11, 2, 18, 8, 8, 9, 6]}\n",
      "{'0': 23, '1': 4, '2': 25, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 48, '1': 31, '2': 37, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 3, '1': 24, '2': 26, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 48, '1': 28, '2': 49, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 47, '1': 36, '2': 45, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 24, '1': 5, '2': 40, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 0, '1': 46, '2': 5, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 48, '1': 46, '2': 0, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 24, '1': 47, '2': 24, 'p': [0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    actions = sample_random_actions(env, obs)\n",
    "    print(actions)\n",
    "    obs, rew, done, info = env.step(actions)\n",
    "    #if any(rew.values()):\n",
    "    #print(rew, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_plot(env, ax, fig):\n",
    "    \"\"\"Plots world state during episode sampling.\"\"\"\n",
    "    plotting.plot_env_state(env, ax)\n",
    "    ax.set_aspect('equal')\n",
    "    display.display(fig)\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "def play_random_episode(env, plot_every=100, do_dense_logging=False):\n",
    "    \"\"\"Plays an episode with randomly sampled actions.\n",
    "    \n",
    "    Demonstrates gym-style API:\n",
    "        obs                  <-- env.reset(...)         # Reset\n",
    "        obs, rew, done, info <-- env.step(actions, ...) # Interaction loop\n",
    "    \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "    # Reset\n",
    "    obs = env.reset(force_dense_logging=do_dense_logging)\n",
    "\n",
    "    # Interaction loop (w/ plotting)\n",
    "    for t in range(env.episode_length):\n",
    "        actions = sample_random_actions(env, obs)\n",
    "        obs, rew, done, info = env.step(actions)\n",
    "\n",
    "        if ((t+1) % plot_every) == 0:\n",
    "            do_plot(env, ax, fig)\n",
    "\n",
    "    if ((t+1) % plot_every) != 0:\n",
    "        do_plot(env, ax, fig)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "play_random_episode(env, plot_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-economist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
