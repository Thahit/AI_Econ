{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gym==0.21\n",
    "#!pip install tensorflow==1.14\n",
    "#!pip install \"ray[rllib]==0.8.4\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside covid19_components.py: 0 GPUs are available.\n",
      "No GPUs found! Running the simulation on a CPU.\n"
     ]
    }
   ],
   "source": [
    "from ai_economist import foundation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tutorials.utils import plotting  # plotting utilities for visualizing env. state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a configuration (dictionary) for the \"gather-trade-build\" environment.\n",
    "\n",
    "env_config_dict = {\n",
    "    # ===== SCENARIO CLASS =====\n",
    "    # Which Scenario class to use: the class's name in the Scenario Registry (foundation.scenarios).\n",
    "    # The environment object will be an instance of the Scenario class.\n",
    "    'scenario_name': 'layout_from_file/hetero_agents',\n",
    "    \n",
    "    # ===== COMPONENTS =====\n",
    "    # Which components to use (specified as list of (\"component_name\", {component_kwargs}) tuples).\n",
    "    #   \"component_name\" refers to the Component class's name in the Component Registry (foundation.components)\n",
    "    #   {component_kwargs} is a dictionary of kwargs passed to the Component class\n",
    "    # The order in which components reset, step, and generate obs follows their listed order below.\n",
    "    'components': [\n",
    "        # (1) Building houses\n",
    "        ('Build', {\n",
    "            'skill_dist':                   'pareto', \n",
    "            'payment_max_skill_multiplier': 3,\n",
    "            'build_labor':                  10,\n",
    "            'payment':                      10\n",
    "        }),\n",
    "        # (2) Trading collectible resources\n",
    "        ('ContinuousDoubleAuction', {\n",
    "            'max_bid_ask':    10,\n",
    "            'order_labor':    0.25,\n",
    "            'max_num_orders': 5,\n",
    "            'order_duration': 50\n",
    "        }),\n",
    "        # (3) Movement and resource collection\n",
    "        ('Gather', {\n",
    "            'move_labor':    1,\n",
    "            'collect_labor': 1,\n",
    "            'skill_dist':    'pareto'\n",
    "        }),\n",
    "        # (4) Planner\n",
    "        ('PeriodicBracketTax', {\n",
    "            'period':          100,\n",
    "            'bracket_spacing': 'us-federal',\n",
    "            'usd_scaling':     1000,\n",
    "            'disable_taxes':   False\n",
    "        })\n",
    "    ],\n",
    "    \n",
    "    # ===== SCENARIO CLASS ARGUMENTS =====\n",
    "    # (optional) kwargs that are added by the Scenario class (i.e. not defined in BaseEnvironment)\n",
    "    'env_layout_file': 'quadrant_25x25_20each_30clump.txt',\n",
    "    'starting_agent_coin': 10,\n",
    "    'fixed_four_skill_and_loc': True,\n",
    "    \n",
    "    # ===== STANDARD ARGUMENTS ======\n",
    "    # kwargs that are used by every Scenario class (i.e. defined in BaseEnvironment)\n",
    "    'n_agents': 4,          # Number of non-planner agents (must be > 1)\n",
    "    'world_size': [25, 25], # [Height, Width] of the env world\n",
    "    'episode_length': 1000, # Number of timesteps per episode\n",
    "    \n",
    "    # In multi-action-mode, the policy selects an action for each action subspace (defined in component code).\n",
    "    # Otherwise, the policy selects only 1 action.\n",
    "    'multi_action_mode_agents': False,\n",
    "    'multi_action_mode_planner': True,\n",
    "    \n",
    "    # When flattening observations, concatenate scalar & vector observations before output.\n",
    "    # Otherwise, return observations with minimal processing.\n",
    "    'flatten_observations': True,\n",
    "    # When Flattening masks, concatenate each action subspace mask into a single array.\n",
    "    # Note: flatten_masks = True is required for masking action logits in the code below.\n",
    "    'flatten_masks': True,\n",
    "    \n",
    "    # How often to save the dense logs\n",
    "    'dense_log_frequency': 1,\n",
    "    \n",
    "    # new\n",
    "    \"env_weighting\" :[0,1,.2,.4],#needs to have len of n agents\n",
    "    \"equ_weighting\": [0,1,.2,.4],\n",
    "    \"mobile_agent_class\": \"HeteroMobileAgent\",#HeteroMobileAgent, BasicMobileAgent\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coin\n",
      "Stone\n",
      "Wood\n"
     ]
    }
   ],
   "source": [
    "env = foundation.make_env_instance(**env_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nfor agent in env.world.agents:\\n    print('Agent {} coin-per-house: {}  evironment weighting: {}  equality weighting: {}'.format(\\n        agent.idx, agent.state['build_payment'], agent.env_weighting, agent.equality\\n        ))\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "'''\n",
    "\n",
    "for agent in env.world.agents:\n",
    "    print('Agent {} coin-per-house: {}  evironment weighting: {}  equality weighting: {}'.format(\n",
    "        agent.idx, agent.state['build_payment'], agent.env_weighting, agent.equality\n",
    "        ))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.world.agents[0].action_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The code for sampling actions (this cell), and playing an episode (below) are general.  \n",
    "# That is, it doesn't depend on the Scenario and Component classes used in the environment!\n",
    "\n",
    "def sample_random_action(agent, mask):\n",
    "    \"\"\"Sample random UNMASKED action(s) for agent.\"\"\"\n",
    "    # Return a list of actions: 1 for each action subspace\n",
    "    if agent.multi_action_mode:\n",
    "        split_masks = np.split(mask, agent.action_spaces.cumsum()[:-1])\n",
    "        return [np.random.choice(np.arange(len(m_)), p=m_/m_.sum()) for m_ in split_masks]\n",
    "\n",
    "    # Return a single action\n",
    "    else:\n",
    "        return np.random.choice(np.arange(agent.action_spaces), p=mask/mask.sum())\n",
    "\n",
    "def sample_random_actions(env, obs):\n",
    "    \"\"\"Samples random UNMASKED actions for each agent in obs.\"\"\"\n",
    "        \n",
    "    actions = {\n",
    "        a_idx: sample_random_action(env.get_agent(a_idx), a_obs['action_mask'])\n",
    "        for a_idx, a_obs in obs.items()\n",
    "    }\n",
    "\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 3, '1': 2, '2': 3, '3': 0, 'p': [3, 11, 19, 10, 0, 3, 11]}\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5a55279346fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_random_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#if any(rew.values()):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#print(rew, done, info)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/AI_Econ/ai_economist/foundation/base/base_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions, seed_state)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_components\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenario_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/AI_Econ/ai_economist/foundation/components/continuous_double_auction.py\u001b[0m in \u001b[0;36mcomponent_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0;31m# Create a bid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                 \u001b[0;32melif\u001b[0m \u001b[0mresource_action\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_bid_ask\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_bid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_payment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresource_action\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    actions = sample_random_actions(env, obs)\n",
    "    print(actions)\n",
    "    obs, rew, done, info = env.step(actions)\n",
    "    #if any(rew.values()):\n",
    "    #print(rew, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_plot(env, ax, fig):\n",
    "    \"\"\"Plots world state during episode sampling.\"\"\"\n",
    "    plotting.plot_env_state(env, ax)\n",
    "    ax.set_aspect('equal')\n",
    "    display.display(fig)\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "def play_random_episode(env, plot_every=100, do_dense_logging=False):\n",
    "    \"\"\"Plays an episode with randomly sampled actions.\n",
    "    \n",
    "    Demonstrates gym-style API:\n",
    "        obs                  <-- env.reset(...)         # Reset\n",
    "        obs, rew, done, info <-- env.step(actions, ...) # Interaction loop\n",
    "    \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "    # Reset\n",
    "    obs = env.reset(force_dense_logging=do_dense_logging)\n",
    "\n",
    "    # Interaction loop (w/ plotting)\n",
    "    for t in range(env.episode_length):\n",
    "        actions = sample_random_actions(env, obs)\n",
    "        obs, rew, done, info = env.step(actions)\n",
    "\n",
    "        if ((t+1) % plot_every) == 0:\n",
    "            do_plot(env, ax, fig)\n",
    "\n",
    "    if ((t+1) % plot_every) != 0:\n",
    "        do_plot(env, ax, fig)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "play_random_episode(env, plot_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-economist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
