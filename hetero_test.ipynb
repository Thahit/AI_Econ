{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gym==0.21\n",
    "#!pip install tensorflow==1.14\n",
    "#!pip install \"ray[rllib]==0.8.4\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside covid19_components.py: 0 GPUs are available.\n",
      "No GPUs found! Running the simulation on a CPU.\n"
     ]
    }
   ],
   "source": [
    "from ai_economist import foundation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tutorials.utils import plotting  # plotting utilities for visualizing env. state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a configuration (dictionary) for the \"gather-trade-build\" environment.\n",
    "\n",
    "env_config_dict = {\n",
    "    # ===== SCENARIO CLASS =====\n",
    "    # Which Scenario class to use: the class's name in the Scenario Registry (foundation.scenarios).\n",
    "    # The environment object will be an instance of the Scenario class.\n",
    "    'scenario_name': 'layout_from_file/hetero_agents',\n",
    "    \n",
    "    # ===== COMPONENTS =====\n",
    "    # Which components to use (specified as list of (\"component_name\", {component_kwargs}) tuples).\n",
    "    #   \"component_name\" refers to the Component class's name in the Component Registry (foundation.components)\n",
    "    #   {component_kwargs} is a dictionary of kwargs passed to the Component class\n",
    "    # The order in which components reset, step, and generate obs follows their listed order below.\n",
    "    'components': [\n",
    "        # (1) Building houses\n",
    "        ('Build', {\n",
    "            'skill_dist':                   'pareto', \n",
    "            'payment_max_skill_multiplier': 3,\n",
    "            'build_labor':                  10,\n",
    "            'payment':                      10,\n",
    "            #\"build_skill\": [.640, .780, .22],#new\n",
    "            \"build_skill\": [.1, .2, .3],#new\n",
    "            #\"build_payment\": [12., 21., 15.],\n",
    "            \"build_payment\": [10, 20, 30],\n",
    "        }),\n",
    "        # (2) Trading collectible resources\n",
    "        ('ContinuousDoubleAuction', {\n",
    "            'max_bid_ask':    10,\n",
    "            'order_labor':    0.25,\n",
    "            'max_num_orders': 5,\n",
    "            'order_duration': 50\n",
    "        }),\n",
    "        # (3) Movement and resource collection\n",
    "        ('Gather', {\n",
    "            'move_labor':    1,\n",
    "            'collect_labor': 1,\n",
    "            'skill_dist':    'pareto',\n",
    "            \"bonus_gather_prob\": [.1,.2,.3]\n",
    "        }),\n",
    "        # (4) Planner\n",
    "        ('PeriodicBracketTax', {\n",
    "            'period':          100,\n",
    "            'bracket_spacing': 'us-federal',\n",
    "            'usd_scaling':     1000,\n",
    "            'disable_taxes':   False\n",
    "        })\n",
    "    ],\n",
    "    \n",
    "    # ===== SCENARIO CLASS ARGUMENTS =====\n",
    "    # (optional) kwargs that are added by the Scenario class (i.e. not defined in BaseEnvironment)\n",
    "    'env_layout_file': 'quadrant_25x25_20each_30clump.txt',\n",
    "    'starting_agent_coin': 10,\n",
    "    'fixed_four_skill_and_loc': False,#new\n",
    "    \n",
    "    # ===== STANDARD ARGUMENTS ======\n",
    "    # kwargs that are used by every Scenario class (i.e. defined in BaseEnvironment)\n",
    "    'n_agents': 3,          # Number of non-planner agents (must be > 1)\n",
    "    'world_size': [25, 25], # [Height, Width] of the env world\n",
    "    'episode_length': 1000, # Number of timesteps per episode\n",
    "    \n",
    "    # In multi-action-mode, the policy selects an action for each action subspace (defined in component code).\n",
    "    # Otherwise, the policy selects only 1 action.\n",
    "    'multi_action_mode_agents': False,\n",
    "    'multi_action_mode_planner': True,\n",
    "    \n",
    "    # When flattening observations, concatenate scalar & vector observations before output.\n",
    "    # Otherwise, return observations with minimal processing.\n",
    "    'flatten_observations': True,\n",
    "    # When Flattening masks, concatenate each action subspace mask into a single array.\n",
    "    # Note: flatten_masks = True is required for masking action logits in the code below.\n",
    "    'flatten_masks': True,\n",
    "    \n",
    "    # How often to save the dense logs\n",
    "    'dense_log_frequency': 1,\n",
    "    \n",
    "    # new\n",
    "    \n",
    "    \"env_weighting\" :[0,.2,.4],#needs to have len of n agents\n",
    "    \"equ_weighting\": [-2,4,8],\n",
    "    \n",
    "    \"mobile_agent_class\": \"HeteroMobileAgent\",#HeteroMobileAgent, BasicMobileAgent\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = foundation.make_env_instance(**env_config_dict)\n",
    "obs = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0 \"build_skill\": 0.1,coin-per-house: 10  evironment weighting: 0  equality weighting: -2\n",
      "Agent 1 \"build_skill\": 0.2,coin-per-house: 20  evironment weighting: 0.2  equality weighting: 4\n",
      "Agent 2 \"build_skill\": 0.3,coin-per-house: 30  evironment weighting: 0.4  equality weighting: 8\n"
     ]
    }
   ],
   "source": [
    "for agent in env.world.agents:\n",
    "    print('Agent {} \"build_skill\": {},coin-per-house: {}  evironment weighting: {}  equality weighting: {}'.format(\n",
    "        agent.idx, agent.state['build_skill'], agent.state['build_payment'], agent.env_weighting, agent.equality\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loc': [14, 11], 'inventory': {'Coin': 10.0, 'Stone': 0, 'Wood': 0}, 'escrow': {'Coin': 0, 'Stone': 0, 'Wood': 0}, 'endogenous': {'Labor': 0}, 'build_payment': 10, 'build_skill': 0.1, 'bonus_gather_prob': 0.1}\n",
      "{'loc': [3, 20], 'inventory': {'Coin': 10.0, 'Stone': 0, 'Wood': 0}, 'escrow': {'Coin': 0, 'Stone': 0, 'Wood': 0}, 'endogenous': {'Labor': 0}, 'build_payment': 20, 'build_skill': 0.2, 'bonus_gather_prob': 0.2}\n",
      "{'loc': [21, 17], 'inventory': {'Coin': 10.0, 'Stone': 0, 'Wood': 0}, 'escrow': {'Coin': 0, 'Stone': 0, 'Wood': 0}, 'endogenous': {'Labor': 0}, 'build_payment': 30, 'build_skill': 0.3, 'bonus_gather_prob': 0.3}\n"
     ]
    }
   ],
   "source": [
    "for agent in env.world.agents:\n",
    "    print(agent.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-dac03efc829d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-dac03efc829d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    agent.\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.world.agents[0].action_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The code for sampling actions (this cell), and playing an episode (below) are general.  \n",
    "# That is, it doesn't depend on the Scenario and Component classes used in the environment!\n",
    "\n",
    "def sample_random_action(agent, mask):\n",
    "    \"\"\"Sample random UNMASKED action(s) for agent.\"\"\"\n",
    "    # Return a list of actions: 1 for each action subspace\n",
    "    if agent.multi_action_mode:\n",
    "        split_masks = np.split(mask, agent.action_spaces.cumsum()[:-1])\n",
    "        return [np.random.choice(np.arange(len(m_)), p=m_/m_.sum()) for m_ in split_masks]\n",
    "\n",
    "    # Return a single action\n",
    "    else:\n",
    "        return np.random.choice(np.arange(agent.action_spaces), p=mask/mask.sum())\n",
    "\n",
    "def sample_random_actions(env, obs):\n",
    "    \"\"\"Samples random UNMASKED actions for each agent in obs.\"\"\"\n",
    "        \n",
    "    actions = {\n",
    "        a_idx: sample_random_action(env.get_agent(a_idx), a_obs['action_mask'])\n",
    "        for a_idx, a_obs in obs.items()\n",
    "    }\n",
    "\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 31, '1': 30, '2': 26, 'p': [19, 0, 9, 10, 3, 12, 8]}\n",
      "{'0': 48, '1': 41, '2': 25, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 40, '1': 8, '2': 49, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 10, '1': 44, '2': 8, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 47, '1': 28, '2': 43, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 18, '1': 49, '2': 46, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 27, '1': 17, '2': 45, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 17, '1': 38, '2': 37, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 35, '1': 44, '2': 27, 'p': [0, 0, 0, 0, 0, 0, 0]}\n",
      "{'0': 48, '1': 10, '2': 17, 'p': [0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    actions = sample_random_actions(env, obs)\n",
    "    print(actions)\n",
    "    obs, rew, done, info = env.step(actions)\n",
    "    #if any(rew.values()):\n",
    "    #print(rew, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_plot(env, ax, fig):\n",
    "    \"\"\"Plots world state during episode sampling.\"\"\"\n",
    "    plotting.plot_env_state(env, ax)\n",
    "    ax.set_aspect('equal')\n",
    "    display.display(fig)\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "def play_random_episode(env, plot_every=100, do_dense_logging=False):\n",
    "    \"\"\"Plays an episode with randomly sampled actions.\n",
    "    \n",
    "    Demonstrates gym-style API:\n",
    "        obs                  <-- env.reset(...)         # Reset\n",
    "        obs, rew, done, info <-- env.step(actions, ...) # Interaction loop\n",
    "    \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "    # Reset\n",
    "    obs = env.reset(force_dense_logging=do_dense_logging)\n",
    "\n",
    "    # Interaction loop (w/ plotting)\n",
    "    for t in range(env.episode_length):\n",
    "        actions = sample_random_actions(env, obs)\n",
    "        obs, rew, done, info = env.step(actions)\n",
    "\n",
    "        if ((t+1) % plot_every) == 0:\n",
    "            do_plot(env, ax, fig)\n",
    "\n",
    "    if ((t+1) % plot_every) != 0:\n",
    "        do_plot(env, ax, fig)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "play_random_episode(env, plot_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-economist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
